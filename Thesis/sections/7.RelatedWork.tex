% !TEX root = ..\main.tex
\chapter{Related Work}\label{ch:RelatedWork}
In this chapter, we present the work related to the topic of this thesis.
As far as we have been able to find, there are no papers that propose a way to model dependencies between two software products. However, there is related work in the area of dependency management and software ecosystem modeling, as well as in the topic of coupling metrics. We present the related work divided into two sections. For each topic, we discuss the papers and summarize the comparison of all the papers at the end of the section.

\section{Software dependencies}

\paragraph{In Dependencies We Trust: How vulnerable are dependencies in software modules? \cite{hejderup2015dependencies}}
The thesis investigates how the vulnerabilities in npm packages create a cascading-effect in the JavaScript ecosystem and how the vulnerabilities are fixed. This is done by studying the vulnerable packages' dependency chain through the packages that depend on these. One of the main contributions of this research is the tool used to find the dependencies between the packages, to determine the impact of the vulnerabilities in the ecosystem, \texttt{Rastogi.js}\footnote{\href{https://github.com/jhejderup/rastogi.js}{https://github.com/jhejderup/rastogi.js}}. The research determined that although only a 1\% of the modules are vulnerable, and that the dependency chain increased the number of vulnerable modules a 39.36\%.

However, in contrast with the dependency metrics developed in this thesis, determining whether a package is affected by a vulnerability with \texttt{Rastorgy.js} is binary evaluation, performed by looking if the package is included as a dependency or not. Therefore, there is no confirmation of whether the dependency is used, or if the part containing the vulnerability is being exploited, since there is no fine-grained evaluation of the dependency. In the conclusions, Hejderup states \textit{"On the other hand, reports of a vulnerable dependency are not an immediate sign of a security weakness in a module. There are several factors to this: the module is used in a development environment, the vulnerable functionality of the dependency is not used, or there is a little risk that the vulnerability can be triggered."}. This sentence points out the need for a more detailed analysis of the usage of the dependencies.

\paragraph{Impact Assessment for Vulnerabilities in Open-Source Software Libraries \cite{plate2015impact}}
Plate et al. create an approach to analyze whether an application, depending on a library that contains a vulnerability, is affected by it or not. Their methodology is meant to help assess the need to update the application with a version that does not use the library's vulnerable version.

The methodology consists of comparing the parts of the library used by the application with the parts updated in the library patch that fixes the vulnerability. It is assumed that those are the parts of the library containing the vulnerable code. The parts of the library used by the application are defined based on a dynamic analysis of the application and the bundled libraries.

In this work, the authors refer to application in the same way we have been using client library. Again, this work focuses only on the impact of vulnerabilities and how to fix them, while this thesis measures the degree of dependency. Moreover, instead of focusing on static analysis as in this thesis, they combine it with dynamic analysis to determine if the application uses the part of the library containing the vulnerability. Nevertheless, these two approaches can be combined to obtain more information about the dependency: while static analysis indicates how the code of the client uses the dependency, the dynamic analysis shows the actual execution, as well as how many times is each part of the application, and the dependency is executed. Just as in this thesis, Plate et al. use \textit{Javassist} for the analysis, since for their proof-of-concept, they focus on Java.

\paragraph{Modeling Library Dependencies and Updates in Large Software Repository Universes \cite{Kula2017}}

In this paper, a model for library dependencies is created. The model is classified as a graph-based Software Universe Graph. It is focused on the updates of the dependencies and shows metrics such as the \textit{wisdom-of-the-crowd}. In addition, it is extended to describe the \textit{adoption-diffusion} and the \textit{co-dependency}. The \textit{adoption-diffusion} studies how the migrations to newer versions of a library are done. The \textit{co-dependencies} are libraries which are usually employed together in an application. This last metric is used to compare different super repositories, Github, and Maven.

In contrast with this thesis, the model is not meant to give information about a particular dependency, but rather indicate the most popular libraries and versions, and how it changes. Therefore, the analysis done to determine whether there is a dependency is not fine-grained but binary. Just as in this thesis, Kula et al. focus on Java, particularly the Maven ecosystem.

\paragraph{PRÄZI: From Package-based to Precise Call-based Dependency Network Analyses \cite{hejderup2018prazi}}
Hejderup et al. create an approach to generate fine-grained call-level dependency networks: \textit{Präzi}. This approach evaluates more precisely the dependencies between software products than a package-level approach. As part of their work, the authors create an implementation of \textit{Präzi} for the Rust's \textit{Crates.io} ecosystem, called \textit{RustPräzi}.

With \textit{RustPräzi}, and to demonstrate how effective the approach is, they perform two case studies. First, a case study that focuses on the propagation of the vulnerabilities across software products, in which they prove the higher accuracy of their approach in comparison to a package-level dependency network. The second case study looks at the impact of deprecation in a library. In this case, with \textit{Präzi}, they can perform an impact analysis of cleaning up deprecated functions.

Hejderup et al. use the word package in the same way we use library in this thesis. Moreover, instead of using the Maven ecosystem for their research, as we have done, and most of the other papers of the domain, they use Rust and \textit{Crates.io}. Furthermore, to create the call-graph of each package, instead of doing a custom analysis, they use a previously existing tool (\textit{LLVM}\footnote{\href{https://github.com/llvm/llvm-project}{https://github.com/llvm/llvm-project}}).

\paragraph{Software ecosystem call graph for dependency management \cite{hejderup2018software}}
In this paper, Hejderup et al. propose extending dependency networks with a versioned call-graph. The authors describe the algorithms used to create the network and how to perform an impact analysis of the changes in a library. Their technique uses the commit time of the products to resolve the dependencies' version ranges, aiming not to miss dependencies with previous library versions. The authors evaluate their dependency network by generating an impact analysis of a particular security bug. The output of the analysis is the part of the dependency network that is impacted by the bug.

Therefore, in this work, Hejderup et al. propose a different approach to create call-level dependency networks, which considers each library's historical data. The focus of the research is an impact analysis of changes and bugs. Nevertheless, the dependency network could also have other applications, such as calculating the metrics proposed in this thesis. The prototype created by Hejderup et al. is focused on JavaScript and the \textit{npm} ecosystem. In this case, to create the call-graph, they used \textit{Jalangi}\footnote{\href{https://github.com/Samsung/jalangi2}{https://github.com/Samsung/jalangi2}}, which uses dynamic analysis.

\paragraph{A Comprehensive Study of Bloated Dependencies in the Maven Ecosystem \cite{soto2020comprehensive}}
Soto-Valero et al. conducted a study of the unused dependencies included in other libraries' dependency tree in the Maven ecosystem. The research includes every type of dependency: direct, transitive, and inherited from the parent module.

To conduct this research, Soto-Valero et al. implemented \texttt{DepClean}\footnote{\href{https://github.com/castor-software/depclean}{https://github.com/castor-software/depclean}}. The tool analyses the dependencies of an artifact by creating a call graph with the libraries involved to define if a dependency is used or not; it is done through bytecode analysis.

Just as this thesis, Soto-Valero et al. focus on Java and the ecosystem of Maven Central. The paper includes a comprehensive study of the unused dependencies in the Maven ecosystem, reported that 75.1\% of the analyzed dependencies were unused dependencies. Nevertheless, the evaluation of the dependencies is still binary, but the strategy used to determine the existence of the dependency is fine-grained. This fine-grained analysis uses bytecode-analysis, just as the proof-of-concept developed in this thesis.

\subsection{Summary}

In Table \ref{table:summary-software-dependencies}, one can find a summary of the comparison between the different papers previously discussed in this section. The papers are first compared according to the terminology they use: library, package, artifact, or application. Then, according to the language and ecosystem used in their prototypes. Next, depending on the type of evaluation done of the dependencies, either binary or fine-grained, and which type of analysis was done. Finally, we also compare the goal, which was the main focus of the paper.

\begin{table}[ht!]
\begin{center}
  \begin{tabular}{|c|l|c|c|c|c|c|c|}
  \hline
   &  & \cite{hejderup2015dependencies} & \cite{plate2015impact} & \cite{Kula2017} & \cite{hejderup2018prazi} & \cite{hejderup2018software} & \cite{soto2020comprehensive} \\ \hline\hline
  \multirow{4}{*}{Terminology} & Library &  & x & x &  & x &  \\ \cline{2-8}
   & Package & x &  &  & x &  &  \\ \cline{2-8}
   & Artifact &  &  &  &  &  & x \\ \cline{2-8}
   & Application &  & x &  &  &  &  \\ \hline\hline
  \multirow{3}{*}{Ecosystem} & Java (Maven) &  & x & x &  &  & x \\ \cline{2-8}
   & JavaScript (npm) & x &  &  &  & x &  \\ \cline{2-8}
   & Rust (Crates.io) &  &  &  & x &  &  \\ \hline\hline
  \multirow{2}{*}{Evaluation} & Binary & x &  & x &  &  &  \\ \cline{2-8}
   & Fine-grained &  & x &  & x & x & x \\ \hline\hline
  \multirow{4}{*}{Analysis} & Source-code &  &  &  &  &  &  \\ \cline{2-8}
   & Bytecode &  & x &  & x &  & x \\ \cline{2-8}
   & Dynamic &  & x &  &  & x &  \\ \cline{2-8}
   & Dependencies file & x &  & x &  &  &  \\ \hline\hline
  \multirow{6}{*}{Goal} & Dependency model &  &  & x &  & x &  \\ \cline{2-8}
   & Impact vulnerabilities & x & x &  & x &  &  \\ \cline{2-8}
   & Impact deprecation &  &  &  & x &  &  \\ \cline{2-8}
   & Impact changes &  &  &  &  & x &  \\ \cline{2-8}
   & Unused dependencies &  &  &  &  &  & x \\ \cline{2-8}
   & Library popularity &  &  & x &  &  &  \\ \hline
  \end{tabular}
\end{center}
\caption{Summary comparison, software dependencies related work}
\label{table:summary-software-dependencies}
\end{table}

As one can see in Table \ref{table:summary-software-dependencies}, the basic terminology, when researching about software dependencies, changes from paper to paper. The reason is that the terms \textit{Library}, \textit{Package}, and \textit{Artifact}, can be used more or less with the same meaning. The difference is that some of these terms are specific for certain software ecosystems (e.g., Maven has artifacts). And the term \textit{Application} is used to denote the software product that uses a library. In the context of this thesis, we have used client library and server library instead. The most used software ecosystems are npm for JavaScript and Maven for Java. This might be because these are two of the largest package repositories. This is precisely the reason for which Hejderup et al. \cite{hejderup2018prazi} decided not to use these two and use \textit{Crates.io} instead.

In evaluating the dependencies, we can see that there is interest in making it more precise. The papers that do a binary evaluation do it by parsing the file where the dependencies are declared and perform the same evaluation as the package manager does. The fine-grained evaluation is done with bytecode analysis or dynamic analysis. In the goals of the papers, we can see that there is interest in determining via a fine-grained evaluation, whether a vulnerability in a library is affecting the client that depends on this library. The same happens for deprecation and changes in a library.

\section{Coupling metrics}

\paragraph{Defining metrics for software components \cite{Vernazza2000}}

Vernazza et al. create a set of metrics for software components. In the paper, software component is defined as a set of classes, similar to how we treat a library as a set of classes to define the coupling metrics. The set of metrics defined in the paper is based on the set of metrics by Chidamber and Kemerer, which include the coupling metrics \textit{CBO} and \textit{RFC}. To validate the metrics created, they use a theoretical approach by using the properties defined by Briand et al. \cite{briand1996property}, just as we did for our coupling metrics. In addition, the authors manually calculate the value of the metrics for various architecture patterns to illustrate their usage.

\paragraph{Detecting Indirect Coupling \cite{yang2005detecting}}

Yang and Berrigan propose a way to measure indirect coupling, which is different from the one suggested by Briand et al. \cite{briand1999unified}, which consists of a transitive closure of the direct coupling. Consider transitive coupling created by more than one type of connection, which differs from the transitive coupling metrics defined in this thesis, focusing on a kind of connection. The authors describe the concept of \textit{use-def} indirect coupling, which is used to identify coupling between the definitions of variables (\textit{def}) and the place where these variables are used (\textit{use}).

Although there is no theoretical validation of the \textit{use-def} indirect coupling, a tool is created to measure this type of coupling in Java projects using source-code analysis. The tool is used to measure the \textit{use-def} indirect coupling in several projects, including the tool itself. With the tool, the authors validate the actionability of \textit{use-def} indirect coupling by relating it to design issues and problems encountered during development.

\paragraph{Measuring Indirect Coupling \cite{Yang2010}}

This thesis by Yang continues with the work done in the last paper \cite{yang2005detecting}. In the thesis, Yang defines a set of indirect coupling metrics based on the \textit{use-def} indirect coupling. In addition, the relation between the metrics and the maintenance effort is also modeled.

The metrics and their relation with maintenance are empirically validated by using a tool developed for this thesis. The tool uses static-code analysis to calculate the set of metrics. First, they calculate the metrics for a corpus of Java projects to see their distribution. The results obtained are similar to those obtained by us in the coupling metrics benchmarking: many loose coupled cases and a few with higher coupling.

The second part of the empirical validation consists of experiments to compare the value of the metrics for different software products and the time the participants needed to resolve certain tasks.

\paragraph{Deriving Coupling Metrics from Call Graphs \cite{Allier2010}}

In this paper, Allier et al. use call-graphs to measure existing coupling metrics. Using call-graphs helps to improve the precision of the measurement since dynamic features used by a system can be accounted for. In particular, they focus on how are polymorphy and dynamic class loading accounted for. Allier et al. use the coupling metrics \textit{CBO} and \textit{RFC} (see Section \ref{section:bg-coupling}), and modify them to account for the dynamic features. The metrics are calculated using call-graphs generated with different techniques. The results show that the call-graph used to calculate the metrics has an important impact on the values.

In this thesis, we have also created our own strategy to account for polymorphy in our coupling metrics. However, we have not included the detection of reflection constructs in the analysis. Using call-graphs to calculate the metrics designed in this thesis could help improve the precision of the measurement. Nevertheless, we would need to generate call-graphs for the entire dependency tree and combine them to create a general call graph. This is not currently available since it is a work in progress within the \textit{FASTEN project}, but it is part of the future work.

\paragraph{Using indirect coupling metrics to predict package maintainability and testability \cite{Almugrin2016}}

In this paper, Almugrin et al. calculated and validated the new indirect coupling metrics they defined in previous work \cite{AlmugrinMelton2015}, which are based on the metrics by Martin \cite{martin2002agile}. The metrics are empirically validated by showing their relationship with maintainability and testability. The experiments done for this validation used previously defined maintainability and testing metrics to compare these metrics' values with the values of the indirect coupling metrics. To run the experiments, they used a set of existing tools and one custom tool to obtain all the necessary data and calculate the values of all the metrics for the seven systems involved in their experiment. The authors calculate the linear regression and correlation between coupling metrics and the maintainability and testability metrics. The results show that the lower values of the coupling metrics tend to have better results for maintainability and testability.

\subsection{Summary}

The summary of the comparison of the papers included in the coupling metrics related work can be found in Table \ref{table:summary-coupling}. The papers are compared according to whether there are new metrics defined or not and if these metrics account for indirect coupling, and the type of coupling measured. Then, we compare the technique used to measure the metrics and the type of validation conducted in the paper.

\begin{table}[ht!]
\begin{center}

\begin{tabular}{|c|l|c|c|c|c|c|}
\hline
&  & \cite{Vernazza2000} & \cite{yang2005detecting} & \cite{Yang2010} & \cite{Allier2010} & \cite{Almugrin2016} \\ \hline\hline
\multirow{2}{*}{Defined new metric(s)} & Yes & x & x & x &  & x \\ \cline{2-7}
& No &  &  &  & x &  \\ \hline\hline
\multirow{2}{*}{Indirect coupling} & Yes &  & x & x &  & x \\ \cline{2-7}
& No & x &  &  & x &  \\ \hline\hline
\multirow{4}{*}{Type of coupling} & Method invocation & x &  &  & x &  \\ \cline{2-7}
& Field access & x &  &  & x &  \\ \cline{2-7}
& use-def &  & x & x &  &  \\ \cline{2-7}
& N/A &  &  &  &  & x \\ \hline\hline
\multirow{3}{*}{Measurement technique} & Source-code analysis &  & x & x &  & x \\ \cline{2-7}
& Call-graph analysis &  &  &  & x &  \\ \cline{2-7}
& Manual calculation & x &  &  &  &  \\ \hline\hline
\multirow{2}{*}{Validation} & Theoretical & x &  &  &  &  \\ \cline{2-7}
& Empirical &  & x & x & x & x \\ \hline
\end{tabular}

\end{center}
\caption{Summary comparison, coupling metrics related work}
\label{table:summary-coupling}
\end{table}

In Table \ref{table:summary-coupling}, it is possible to see that most of the papers included in the related work create new coupling metrics, two of them by adapting previously existing metrics \cite{Vernazza2000, Almugrin2016} and the other two are focused on a type of coupling which has not been measured before: \textit{use-def} \cite{yang2005detecting, Yang2010}. Allier et al. \cite{Allier2010}, instead of creating new metrics, evaluate how much the value of the metrics change, depending on which technique is used to calculate them, they compare different call-graph generators based on how they deal with inheritance. There is source-code analysis in the related work about coupling metrics, which was not used in any of the papers related to software dependencies. This seems to be because the papers about coupling metrics analyze only one software product at a time. In contrast, the papers about software dependencies analyze dependency trees or even entire ecosystems, making other options such as bytecode or dynamic analysis a better option. Four out of the five papers do an empirical validation of their work. Two of the papers validate their metrics by looking at the effect these have in terms of maintainability \cite{Yang2010, Almugrin2016}. Yang and Berrigan \cite{yang2005detecting}, compare the places of their tool with \textit{use-def} coupling, with the places where they had issues during development, and finally, Allier et al. \cite{Allier2010} compare the results obtained with different call-graphs generators.
